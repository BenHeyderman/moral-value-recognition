{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moral Value Recognition\n",
    "_Ben Heyderman_\n",
    "\n",
    "This notebook presents the practical implementation of the paper _Predicting Lyric Morality Through Handcrafted Audio Features_, which was submitted as the final project for the Sound and Music Computing MSc course at Queen Mary University of London."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Gather Spotify Previews and Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum requirement for the project is a csv file with one column containing song names and song titles. This can be used to find song lyrics and previews.\n",
    "\n",
    "1. Song lyrics can be scraped from Genius using the utils_get_lyrics script in the supporting scripts folder. Note: WASABI API includes lyrics (not GitHub version) so it could be quicker to access through there\n",
    "2. Previews are obtained in a two step process: finding the preview url (utils_get_previews) and downloading the preview (utils_download_previews). I have included a class I wrote for scraping information from Spotify which has some useful functionality beyond what is used in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Extract Features and Construct Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done using the utils_construct_dataset script which uses functions from the audiofeatureextractor class I created.\n",
    "- A combination of bespoke (some origional and some adapted from other work - see class for details) and features from the Essentia library are extracted.\n",
    "- The dataset is stored as a dictionary in which features are organised by category (allowing easy categorical elimination)\n",
    "- The class includes a function to convert these dictionaries into Pandas dataframes ready for xgboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Moral Value Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Moral values are extracted using a model created by Vjosa Preniqi. This cannot be included in this as it is not public/my own work.\n",
    "- The remainder of this notebook assumes the moral values are extracted and added as additional columns to the the feature dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV # cross validation\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sage\n",
    "import shap\n",
    "import itertools\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_identifier = \"WASABI\"\n",
    "df = pd.read_csv(f\"dataset_{dataset_identifier}_MFT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution\n",
    "\n",
    "# Get first 10 columns (mft columns)\n",
    "selected_columns = ['care', 'harm', 'fairness', 'cheating', 'loyalty', 'betrayal', 'authority', 'subversion', 'purity', 'degradation']\n",
    "selected_df = df[selected_columns]\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot a histogram for each mft\n",
    "for i, column in enumerate(selected_columns):\n",
    "    axes[i].hist(selected_df[column].dropna(), bins=30, color='skyblue')\n",
    "    axes[i].set_title(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_split_dataset_classifier(df, mft, columns_to_drop):\n",
    "    \"\"\"\n",
    "    Prepare and split the dataset for classification.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input dataframe containing the data.\n",
    "    mft (str): The name of the main feature target column.\n",
    "    columns_to_drop (list): List of column names to drop from the dataframe.\n",
    "\n",
    "    Returns:\n",
    "    X (DataFrame): The feature set.\n",
    "    y (DataFrame): The target set.\n",
    "    X_train (DataFrame): The training set features.\n",
    "    X_test (DataFrame): The test set features.\n",
    "    y_train (DataFrame): The training set target.\n",
    "    y_test (DataFrame): The test set target.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter the dataframe to only include low and high feature target values\n",
    "    df_filtered = df[(df[mft] <= 0.2) | (df[mft] >= 0.6)]\n",
    "    \n",
    "    # Round the main feature target values to the nearest integer (binary classification)\n",
    "    df_filtered.loc[:, mft] = df_filtered[mft].round(0)\n",
    "    \n",
    "    # Create the target set\n",
    "    y = df_filtered[[mft]].copy()\n",
    "\n",
    "    # Drop specified columns to create the feature set\n",
    "    X = df_filtered.drop(columns_to_drop, axis=1).copy() \n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    # Y stratified so equal distribution of y in training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "    return X, y, X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_best_model_classifier(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train and select the best classifier model using GridSearchCV.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (DataFrame): The training set features.\n",
    "    y_train (DataFrame): The training set target.\n",
    "\n",
    "    Returns:\n",
    "    best_model (XGBClassifier): The best classifier model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 6],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'reg_lambda': [0.5, 1.0, 1.5],\n",
    "        'reg_alpha': [0.5, 1.0, 1.5]\n",
    "    }\n",
    "\n",
    "    # Calculate scale_pos_weight to handle class imbalance\n",
    "    scale_pos_weight = (y_train.values == 0).sum() / (y_train.values == 1).sum()\n",
    "    \n",
    "    # Initialize the XGBClassifier\n",
    "    xgb_class = xgb.XGBClassifier(objective='binary:logistic', \n",
    "                                  seed=42,\n",
    "                                  subsample=0.9,\n",
    "                                  eval_metric='auc',\n",
    "                                  scale_pos_weight=scale_pos_weight,\n",
    "                                  colsample_bytree=0.5)\n",
    "\n",
    "    # Initialize GridSearchCV with 3-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=xgb_class, param_grid=param_grid, cv=3, n_jobs=-1, scoring='roc_auc', verbose=1)\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Train the best model with the best parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "def save_data(filename, data):\n",
    "    \"\"\"\n",
    "    Save the data to a file.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The name of the file to save the data.\n",
    "    data: The data to be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, 'wb') as fp:\n",
    "        pickle.dump(data, fp)\n",
    "        print('data saved successfully to file.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of 10 mfts used in the study\n",
    "mft_list = ['care','harm','fairness','cheating','loyalty','betrayal','authority','subversion','purity','degradation']\n",
    "\n",
    "# Columns to be removed from the training set\n",
    "columns_to_drop = mft_list + [\"file_id\"]\n",
    "\n",
    "imbalance_method = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model for each of the MFTs\n",
    "\n",
    "# If blank the class imbalance is being addressed using weighting in the xgboost classifier\n",
    "\n",
    "for mft in mft_list:\n",
    "    print(f\"Training model {mft}:\")\n",
    "    print(\"Splitting data...\")\n",
    "    \n",
    "    # Use above function to prepare the dataset\n",
    "    _, _, X_train, X_test, y_train, y_test = prep_split_dataset_classifier(df, mft, columns_to_drop)\n",
    "\n",
    "    # Optional alternative methods for addressing class imbalance.\n",
    "    # Uncomment one method at a time\n",
    "\n",
    "    '''# ROS\n",
    "    imbalance_method = \"_ROS\"\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    # fit predictor and target variable\n",
    "    X_train, y_train = ros.fit_resample(X_train, y_train)'''\n",
    "    \n",
    "    '''# SMOTE\n",
    "    imbalance_method = \"_SMOTE\"\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)'''\n",
    "\n",
    "    # Perform gridsearch using the above function\n",
    "    print(\"Grid search...\")\n",
    "    best_model = get_best_model_classifier(X_train, y_train)\n",
    "    print(\"Best model found.\")  \n",
    "        \n",
    "    # Predict on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate f1 to assess performance\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"F1: {f1}\")\n",
    "\n",
    "    # Save model\n",
    "    filename = f\"best_model_{dataset_identifier}_{mft}{imbalance_method}.pkl\"\n",
    "    save_data(filename, best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validated Recurssive Feature Elimination (RFE)\n",
    "\n",
    "f1_grid_searched = {}\n",
    "\n",
    "for mft in mft_list:\n",
    "    print(f\"Training model {mft}:\")\n",
    "    selected_features = {}\n",
    "    f1 = {}\n",
    "\n",
    "    # Use above function to prepare the dataset\n",
    "    print(\"Splitting data...\")\n",
    "    _, _, X_train, X_test, y_train, y_test = prep_split_dataset_classifier(df, mft, columns_to_drop)\n",
    "\n",
    "    print(\"Running RFE\")\n",
    "\n",
    "    # Calculate scale_pos_weight\n",
    "    num_positives = y_train.sum().item()\n",
    "    num_negatives = len(y_train) - num_positives\n",
    "    scale_pos_weight = (num_negatives / num_positives)\n",
    "    \n",
    "    # Define the model with the calculated scale_pos_weight\n",
    "    model = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "    # perform RFE\n",
    "    rfe = RFECV(estimator=model, cv=StratifiedKFold(5), min_features_to_select=1, step=1, scoring=\"f1\")\n",
    "    rfe = rfe.fit(X_train, y_train)\n",
    "    selected_features = rfe.support_\n",
    "    \n",
    "    # Remove unused features from the dataset\n",
    "    X_test = X_test.iloc[:, selected_features]\n",
    "    X_train= X_train.iloc[:, selected_features]\n",
    "\n",
    "    # Gridsearch on using reduced feature set\n",
    "    print(\"Performing Grid Search\")\n",
    "    best_model = get_best_model_classifier(X_train, y_train)\n",
    "\n",
    "    print(\"Best model found.\")\n",
    "\n",
    "    # Make predictions from best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate f1 score\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f1_grid_searched[mft] = f1\n",
    "    print(f\"Grid Searched F1: {f1}\")\n",
    "\n",
    "    # Save model and feature selection\n",
    "    filename = f'reduced_feature_models/RFE_{dataset_identifier}_{mft}_best_model.pkl'\n",
    "    save_data(filename, best_model)\n",
    "\n",
    "    filename = f'reduced_feature_models/RFE_{dataset_identifier}_{mft}_best_featureset.pkl'\n",
    "    save_data(filename, selected_features)\n",
    "\n",
    "print(\"\\nPrint F1s:\")\n",
    "print(f1_grid_searched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supporting_scripts.audiofeatureextractor import DatasetConstructor\n",
    "\n",
    "def get_data_by_category(included_categories, full_dataset_path):\n",
    "    \"\"\"\n",
    "    Load the dataset and filter it by the specified categories.\n",
    "\n",
    "    Parameters:\n",
    "    included_categories (list): List of categories to include in the filtered dataset.\n",
    "    full_dataset_path (str): Path to the full dataset file.\n",
    "\n",
    "    Returns:\n",
    "    df (DataFrame): The filtered dataset as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open and load the dataset from the specified file path\n",
    "    with open(full_dataset_path, 'rb') as f:\n",
    "        dataset_dict = pickle.load(f)\n",
    "    \n",
    "    # Convert the dataset dictionary to a DataFrame and filter by the specified categories\n",
    "    df = DatasetConstructor.dict2df(dataset_dict, included_categories=included_categories, save_dataset=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_unique_combinations(section_list):\n",
    "    \"\"\"\n",
    "    Generate all unique combinations of the sections given.\n",
    "\n",
    "    Parameters:\n",
    "    section_list (list): List of sections to generate combinations from.\n",
    "\n",
    "    Returns:\n",
    "    list: List of unique combinations, each combination also retains the MFT features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty list to store all combinations\n",
    "    all_combinations = []\n",
    "\n",
    "    # Iterate over the range from 1 to the length of the section list\n",
    "    for i in range(1, len(section_list) + 1):\n",
    "        # Generate combinations of the current length\n",
    "        combinations = itertools.combinations(section_list, i)\n",
    "        # Extend the all_combinations list with the new combinations\n",
    "        all_combinations.extend(combinations)\n",
    "    \n",
    "    # Convert each combination to a list and append \"mft\" to it\n",
    "    return [list(comb) + [\"mft\"] for comb in all_combinations]\n",
    "\n",
    "# Get unique combinations based on feature categories\n",
    "sections = ['timbre','dynamics','rhythm','harmony','melody']\n",
    "unique_combinations = get_unique_combinations(sections)\n",
    "\n",
    "print(f\"Number of models: {len(unique_combinations)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct category elemination feature selection\n",
    "\n",
    "f1_values_feature_comparison = {}\n",
    "\n",
    "#create blank nested dictionary for f1 scores\n",
    "for mft in mft_list:\n",
    "    f1_values_feature_comparison[mft] = {}\n",
    "\n",
    "# For each combination of the category\n",
    "for unique_combination in unique_combinations:\n",
    "    # Get the right columsn of the dataset\n",
    "    df_by_category = get_data_by_category(unique_combination)\n",
    "\n",
    "    print(f\"Current combination: {', '.join(unique_combination[:-1])}\")\n",
    "    print(f'The number of columns in the DataFrame is: {df.shape[1]}\\n')\n",
    "    # For each mft find the best model\n",
    "    for mft in mft_list:\n",
    "        print(f\"Training model {mft}:\")\n",
    "        print(\"Splitting data...\")\n",
    "        _, _, X_train, X_test, y_train, y_test = prep_split_dataset_classifier(df_by_category, mft, columns_to_drop)\n",
    "        \n",
    "        # Perform gridsearch\n",
    "        print(\"Grid search...\")\n",
    "        best_model = get_best_model_classifier(X_train, y_train)\n",
    "        \n",
    "        # Save data\n",
    "        filename = f\"reduced_feature_models/category_elim_{dataset_identifier}_{mft}_{'_'.join(unique_combination[:-1])}\"\n",
    "        save_data(filename, best_model)\n",
    "\n",
    "        # Calculate f1 score\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1_values_feature_comparison[mft][', '.join(unique_combination[:-1])] = f1\n",
    "        print(f\"f1: {f1}\\n\")\n",
    "\n",
    "# Convert f1 dictionary to DataFrame\n",
    "df_f1 = pd.DataFrame(f1_values_feature_comparison)\n",
    "print(df_f1)\n",
    "df_f1.to_csv(\"f1_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-polar model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df_bill = pd.read_csv(\"dataset_billboard_MFT.csv\")\n",
    "df_WASABI = pd.read_csv(\"dataset_WASABI_MFT.csv\")\n",
    "\n",
    "df_morality = pd.concat([df_bill, df_WASABI], ignore_index=True)\n",
    "\n",
    "# Categorise moral and immoral MFTs\n",
    "moral_headers = ['care','fairness','loyalty','authority','purity']\n",
    "immoral_headers = ['harm','cheating','betrayal','subversion','degradation']\n",
    "\n",
    "# Add new column for morality\n",
    "df_morality['moral'] = None\n",
    "\n",
    "# Check for the conditions and set 'moral' column values\n",
    "for i, row in df_morality.iterrows():\n",
    "    moral_condition = (row[moral_headers] > 0.6).any() and (row[immoral_headers] <= 0.2).all()\n",
    "    immoral_condition = (row[immoral_headers] > 0.6).any() and (row[moral_headers] <= 0.2).all()\n",
    "    \n",
    "    if moral_condition:\n",
    "        df_morality.at[i, 'moral'] = 1\n",
    "    elif immoral_condition:\n",
    "        df_morality.at[i, 'moral'] = 0\n",
    "\n",
    "# Remove rows that are morally ambiguous\n",
    "df_morality = df_morality.dropna(subset=['moral'])\n",
    "\n",
    "# Make sure 'moral' column is of int type\n",
    "df_morality['moral'] = df_morality['moral'].astype(int)\n",
    "\n",
    "# Save data\n",
    "df_morality.to_csv('dataset_with_morality.csv', index=False)\n",
    "print(df_morality.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance_method = \"\"\n",
    "\n",
    "print(\"Splitting data...\")\n",
    "\n",
    "# Use above function to prepare the dataset\n",
    "_, _, X_train, X_test, y_train, y_test = prep_split_dataset_classifier(df_morality, \"moral\", columns_to_drop+[\"moral\"])\n",
    "\n",
    "# Perform gridsearch using the above function\n",
    "print(\"Grid search...\")\n",
    "best_model = get_best_model_classifier(X_train, y_train)\n",
    "print(\"Best model found.\")  \n",
    "    \n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate f1 to test performance\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1: {f1}\")\n",
    "\n",
    "# Save model\n",
    "filename = f\"best_model_combined_data_moral{imbalance_method}.pkl\"\n",
    "save_data(filename, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Dataset validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize the dictionary\n",
    "f1s = {\"billboard\": {}, \"WASABI\": {}}\n",
    "\n",
    "# Load the datasets\n",
    "df_bill = pd.read_csv(\"dataset_billboard_MFT.csv\")\n",
    "df_WASABI = pd.read_csv(\"dataset_WASABI_MFT.csv\")\n",
    "\n",
    "def calculate_f1_scores(df, dataset_identifier):\n",
    "    \"\"\"\n",
    "    Load model and get f1 score.\n",
    "\n",
    "    Parameters:\n",
    "    df (Dataframe): Data\n",
    "    dataset_identifier (str):  Name of the dataset being analysed\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for mft in mft_list:\n",
    "        # Get data\n",
    "        X, y, _, _, _, _ = prep_split_dataset_classifier(df, mft, columns_to_drop)\n",
    "\n",
    "        # Load model\n",
    "        filename = f\"best_model_{dataset_identifier}_{mft}{imbalance_method}.pkl\"\n",
    "        with open(filename, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "\n",
    "        y_pred = model.predict(X)\n",
    "        # Calculate f1 to test performance\n",
    "        f1 = f1_score(y, y_pred)\n",
    "\n",
    "        f1s[dataset_identifier][mft] = f1\n",
    "\n",
    "# Calculate F1 scores for each dataset/model combination\n",
    "calculate_f1_scores(df_WASABI, \"billboard\")\n",
    "calculate_f1_scores(df_bill, \"WASABI\")\n",
    "\n",
    "# Create a list of keys (moral values) and indices\n",
    "keys = list(f1s[\"WASABI\"].keys())\n",
    "indices = np.arange(len(keys))\n",
    "\n",
    "# Width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Plot the f1 values for both sets\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(indices, f1s[\"billboard\"].values(), bar_width, color='skyblue', label='Train: Billboard, Test: WASABI')\n",
    "plt.bar(indices + bar_width, f1s[\"WASABI\"].values(), bar_width, color='grey', label='Train: WASABI, Test: Billboard')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Moral Value')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Cross-Dataset Validation')\n",
    "plt.xticks(indices + bar_width / 2, keys, rotation=45)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each MFT, calculate SAGE values\n",
    "for mft in [\"care\", \"harm\", \"cheating\", \"subversion\", \"degradation\"]:\n",
    "    # Get data\n",
    "    print(f\"Getting data...\")\n",
    "    X, y, _,_,_,_ = prep_split_dataset_classifier(df, mft, columns_to_drop)\n",
    "    print(\"Loading model...\")\n",
    "\n",
    "    # Load model\n",
    "    filename = f\"best_model_{dataset_identifier}_{mft}{imbalance_method}.pkl\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    print(\"Getting sage...\")\n",
    "    # Calculate SAGE\n",
    "    imputer = sage.MarginalImputer(model, X[:128].to_numpy())\n",
    "    estimator = sage.PermutationEstimator(imputer, \"cross entropy\")\n",
    "    sage_values = estimator(X.to_numpy(), y.to_numpy())\n",
    "    sage_values.plot(X.columns, max_features=10, orientation=\"horizontal\", color=\"skyblue\")\n",
    "    print(\"Saving sage...\")\n",
    "    filename = f'sage_{dataset_identifier}_{mft}{imbalance_method}.pkl'\n",
    "    with open(filename, 'wb') as fp:\n",
    "        pickle.dump(sage_values, fp)\n",
    "        print('Explanation saved successfully to file\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each MFT, plot sage values\n",
    "for mft in mft_list:\n",
    "    print(f\"Current MFT: {mft}\")\n",
    "    filename = f'sage_{dataset_identifier}_{mft}{imbalance_method}.pkl'\n",
    "    with open(filename, 'rb') as f:\n",
    "        sage_values = pickle.load(f)\n",
    "    X, y, _,_,_,_ = prep_split_dataset_classifier(\"subversion\", columns_to_drop)\n",
    "    sage_values.plot(X.columns, max_features=10, orientation=\"horizontal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate SHAP\n",
    "imbalance_method = \"\"\n",
    "\n",
    "# For each MFT, calculate shap values\n",
    "for mft in mft_list:\n",
    "    # Get data\n",
    "    print(\"Getting data...\")\n",
    "    X, _, _,_,_,_ = prep_split_dataset_classifier(df, mft, columns_to_drop)\n",
    "    print(\"Loading model...\")\n",
    "\n",
    "    # Load the model\n",
    "    filename = f\"best_model_{dataset_identifier}_{mft}{imbalance_method}.pkl\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    print(\"Getting SHAP...\")\n",
    "\n",
    "    # Float 64 required for SHAP library\n",
    "    X = X.astype('float64')\n",
    "\n",
    "    # Compute SHAP values\n",
    "    explainer = shap.Explainer(model, X)\n",
    "    shap_values = explainer(X)    \n",
    "    \n",
    "    print(\"Saving SHAP...\")\n",
    "    filename = f'shap_{dataset_identifier}_{mft}{imbalance_method}.pkl'\n",
    "    # save dictionary \n",
    "    with open(filename, 'wb') as fp:\n",
    "        pickle.dump(shap_values, fp)\n",
    "        print('Explanation saved successfully to file\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up colours for Beeswarm plot\n",
    "colors = [\"grey\",\"skyblue\"]\n",
    "cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors)\n",
    "\n",
    "# Plot Beeswarm plot of SHAP values\n",
    "for mft in mft_list:\n",
    "    print(f\"Current MFT: {mft}\")\n",
    "    filename = f'shap_{dataset_identifier}_{mft}{imbalance_method}.pkl'\n",
    "    with open(filename, 'rb') as f:\n",
    "        shap_values = pickle.load(f)\n",
    "        shap.plots.beeswarm(shap_values, color=cmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
